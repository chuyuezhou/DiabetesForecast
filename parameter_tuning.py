import pandas as pd
import numpy as np
import seaborn as sns
import joblib
import os
import time
import optuna
from optuna.samplers import TPESampler
from optuna.pruners import HyperbandPruner
from matplotlib import gridspec
from mpl_toolkits.axes_grid1 import make_axes_locatable
from scipy.interpolate import griddata
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, confusion_matrix
from sklearn.model_selection import train_test_split, cross_val_score

import matplotlib.pyplot as plt
import matplotlib as mpl


mpl.use('TkAgg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯é¿å…PyCharmå…¼å®¹æ€§é—®é¢˜

# 2. è®¾ç½®å­—ä½“æ”¯æŒ - è§£å†³ä¸­æ–‡å­—ç¬¦æ˜¾ç¤ºé—®é¢˜
plt.rcParams['font.sans-serif'] = ['SimHei']  # Windowsä¸­æ–‡å­—ä½“
plt.rcParams['axes.unicode_minus'] = False    # æ­£ç¡®æ˜¾ç¤ºè´Ÿå·


# è®¾ç½®å›¾è¡¨æ ·å¼
plt.style.use('seaborn-v0_8-bright')
sns.set_palette("Set2")

# è®¾ç½®ç»“æœç›®å½•
os.makedirs('models', exist_ok=True)
os.makedirs('results/optuna_plots', exist_ok=True)

# è®¾ç½®éšæœºç§å­
SEED = 42
np.random.seed(SEED)

# 2. åŠ è½½å’Œå‡†å¤‡æ•°æ®
print("åŠ è½½å’Œå¤„ç†æ•°æ®...")
# è¿™é‡Œä½¿ç”¨æ‚¨çš„å®é™…æ•°æ®åŠ è½½ä»£ç 

# åŠ è½½å¤„ç†åçš„æ•°æ®
data = pd.read_csv('data/filled_diabetes_data.csv')

# å®šä¹‰ç‰¹å¾å’Œç›®æ ‡å˜é‡
features = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke',
            'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',
            'HvyAlcoholConsump', 'AnyHealthcare', 'MentHlth', 'PhysHlth',
            'DiffWalk', 'Sex', 'Age']
target = 'Diabetes_binary'

# åˆ†å‰²ç‰¹å¾å’Œç›®æ ‡
X = data.drop('Diabetes_binary', axis=1)
y = data['Diabetes_binary']

# åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=SEED
)

print(f"è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬ (é˜³æ€§ç‡: {y_train.mean():.4f})")
print(f"æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬ (é˜³æ€§ç‡: {y_test.mean():.4f})")


# 3. è´å¶æ–¯ä¼˜åŒ–å‡½æ•°
def objective(trial):
    """Optunaä¼˜åŒ–ç›®æ ‡å‡½æ•°"""
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 500),
        'max_depth': trial.suggest_int('max_depth', 3, 30),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
        'max_features': trial.suggest_float('max_features', 0.1, 0.99),
        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),
        'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),
        'random_state': SEED
    }

    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = RandomForestClassifier(**params, n_jobs=-1)

    # 3æŠ˜äº¤å‰éªŒè¯çš„ROC AUC
    scores = cross_val_score(
        model,
        X_train,
        y_train,
        cv=3,
        scoring='roc_auc',
        n_jobs=1
    )

    return np.mean(scores)


# 4. åˆ›å»ºä¼˜åŒ–ç ”ç©¶
def optimize_hyperparameters(n_trials=50):
    """è¿è¡Œè´å¶æ–¯ä¼˜åŒ–ç ”ç©¶"""
    print(f"\nå¼€å§‹è´å¶æ–¯ä¼˜åŒ–ï¼Œæœ€å¤§è¿­ä»£æ¬¡æ•°: {n_trials}...")

    sampler = TPESampler(seed=SEED)
    pruner = HyperbandPruner()

    study = optuna.create_study(
        direction='maximize',
        sampler=sampler,
        pruner=pruner
    )

    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)

    print(f"ä¼˜åŒ–å®Œæˆ! æœ€ä½³è¯•éªŒ: {study.best_trial.number}")
    print(f"æœ€ä½³AUC: {study.best_value:.4f}")
    print(f"æœ€ä½³å‚æ•°: {study.best_params}")

    return study


# 5. æ‰§è¡Œä¼˜åŒ–
start_time = time.time()
study = optimize_hyperparameters(n_trials=50)
optimization_time = time.time() - start_time

print(f"\nâ± ä¼˜åŒ–è€—æ—¶: {optimization_time:.2f}ç§’")
print(f"å¹³å‡æ¯æ¬¡è¯•éªŒè€—æ—¶: {optimization_time / 50:.2f}ç§’")

# 6. ä¿å­˜æœ€ä½³æ¨¡å‹
best_params = study.best_params
best_model = RandomForestClassifier(**best_params, random_state=SEED, n_jobs=-1)

# åœ¨æ•´ä¸ªè®­ç»ƒé›†ä¸Šé‡æ–°è®­ç»ƒ
print("\nä½¿ç”¨æœ€ä½³å‚æ•°é‡æ–°è®­ç»ƒæ¨¡å‹...")
best_model.fit(X_train, y_train)

# ä¿å­˜æ¨¡å‹
joblib.dump(best_model, 'models/rf_optuna_optimized.pkl')
print("ä¼˜åŒ–æ¨¡å‹å·²ä¿å­˜è‡³ models/rf_optuna_optimized.pkl")

# 7. è¯„ä¼°æœ€ç»ˆæ¨¡å‹
y_pred_prob = best_model.predict_proba(X_test)[:, 1]
test_auc = roc_auc_score(y_test, y_pred_prob)
print(f"\nğŸ¯ æµ‹è¯•é›†AUC: {test_auc:.4f}")

# 8. ä½¿ç”¨Matplotlibåˆ›å»ºæ‰€æœ‰å¯è§†åŒ–
print("\nä½¿ç”¨Matplotlibç”Ÿæˆä¼˜åŒ–è¿‡ç¨‹å¯è§†åŒ–...")
trials_df = study.trials_dataframe()

# 8.1 ä¼˜åŒ–å†å²å›¾
plt.figure(figsize=(12, 6))
plt.plot(trials_df['number'], trials_df['value'], 'o-', markersize=4, linewidth=1.5, alpha=0.7)
plt.scatter(study.best_trial.number, study.best_value, s=150, c='red', zorder=5)
plt.annotate(f'Best trial\nAUC={study.best_value:.4f}',
             (study.best_trial.number, study.best_value),
             xytext=(10, -20),
             textcoords='offset points',
             arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=-0.2"))
plt.xlabel('Trial Number')
plt.ylabel('Validation AUC')
plt.title('Optimization History')
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.savefig('results/optuna_plots/optimization_history.png', dpi=300, bbox_inches='tight')
plt.close()
print("ä¼˜åŒ–å†å²å›¾å·²ä¿å­˜")

# 8.2 å‚æ•°é‡è¦æ€§å›¾
# è®¡ç®—å‚æ•°é‡è¦æ€§
param_importance = {}
for param in trials_df.columns:
    if param.startswith('params_') and trials_df[param].nunique() > 1:
        # ä½¿ç”¨çš®å°”é€Šç›¸å…³ç³»æ•°ä½œä¸ºé‡è¦æ€§çš„ç®€åŒ–åº¦é‡
        correlation = trials_df['value'].corr(trials_df[param], method='pearson')
        param_importance[param.replace('params_', '')] = abs(correlation)

# è½¬æ¢ä¸ºDataFrameå¹¶æ’åº
importance_df = pd.DataFrame(list(param_importance.items()), columns=['Parameter', 'Importance'])
importance_df = importance_df.sort_values('Importance', ascending=False)

# æ›´æ–°å‚æ•°é‡è¦æ€§å›¾
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Parameter', data=importance_df,
            hue='Parameter', palette='viridis_r', legend=False, dodge=False)
plt.title('Hyperparameter Importance')
plt.xlabel('Correlation Magnitude (|Ï|)')
plt.ylabel('Hyperparameter')
plt.grid(axis='x', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.savefig('results/optuna_plots/param_importance.png', dpi=300, bbox_inches='tight')
plt.close()
print("å‚æ•°é‡è¦æ€§å›¾å·²ä¿å­˜")


# 8.3 å¹¶è¡Œåæ ‡å›¾ (æ”¹è¿›ç‰ˆæ•£ç‚¹å›¾çŸ©é˜µ)
# é€‰æ‹©æœ€é‡è¦çš„4ä¸ªå‚æ•°
if len(importance_df) > 4:
    top_params = importance_df.head(4)['Parameter'].tolist()
else:
    top_params = importance_df['Parameter'].tolist()

fig = plt.figure(figsize=(16, 12))

# åˆ›å»ºæ•£ç‚¹å›¾çŸ©é˜µ
# æ›´æ–°æ ¸å¯†åº¦å›¾
for i, param1 in enumerate(top_params):
    for j, param2 in enumerate(top_params):
        ax = plt.subplot(len(top_params), len(top_params), i * len(top_params) + j + 1)

        if i == j:  # å¯¹è§’çº¿ - æ ¸å¯†åº¦å›¾
            sns.kdeplot(trials_df[f'params_{param1}'], fill=True, ax=ax, color='skyblue')  # æ”¹ä¸º fill=True
            ax.set_title(f'Distribution of {param1}')
        else:
            scatter = ax.scatter(trials_df[f'params_{param1}'], trials_df[f'params_{param2}'],
                                 c=trials_df['value'], cmap='viridis', alpha=0.7, s=20)
            # é«˜äº®æœ€ä½³è¯•éªŒ
            ax.scatter(study.best_trial.params.get(param1), study.best_trial.params.get(param2),
                       s=150, c='red', zorder=5, edgecolors='white')

            ax.set_xlabel(param1)
            ax.set_ylabel(param2)

            # åªåœ¨å³ä¾§å’Œæœ€ä¸‹è¾¹æ·»åŠ é¢œè‰²æ¡
            if j == len(top_params) - 1 and i < len(top_params) - 1:
                divider = make_axes_locatable(ax)
                cax = divider.append_axes('right', size='5%', pad=0.1)
                plt.colorbar(scatter, cax=cax).set_label('AUC Score')

        if j == 0:
            ax.set_ylabel(param1)
        if i == len(top_params) - 1:
            ax.set_xlabel(param2)

plt.suptitle('Hyperparameter Relationships', fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.97])
plt.savefig('results/optuna_plots/param_relationships.png', dpi=300, bbox_inches='tight')
plt.close()
print("å‚æ•°å…³ç³»å›¾å·²ä¿å­˜")

# 8.4 çƒ­åŠ›å›¾æ›¿ä»£
if 'params_n_estimators' in trials_df and 'params_max_depth' in trials_df:
    # å‡†å¤‡æ•°æ®
    n_est = trials_df['params_n_estimators']
    max_dep = trials_df['params_max_depth']
    auc_values = trials_df['value']

    # åˆ›å»ºç½‘æ ¼
    xi = np.linspace(min(n_est), max(n_est), 100)
    yi = np.linspace(min(max_dep), max(max_dep), 100)
    zi = griddata((n_est, max_dep), auc_values, (xi[None, :], yi[:, None]), method='cubic')

    plt.figure(figsize=(10, 8))

    # ç­‰é«˜çº¿å›¾
    contour = plt.contourf(xi, yi, zi, levels=20, cmap='viridis', alpha=0.8)
    plt.colorbar(contour).set_label('Validation AUC')

    # æœ€ä½³ç‚¹æ ‡è®°
    best_n = study.best_params.get('n_estimators')
    best_d = study.best_params.get('max_depth')
    if best_n and best_d:
        plt.scatter(best_n, best_d, s=200, c='red', edgecolors='white', linewidth=1.5, zorder=5)
        plt.annotate(f'Best point\nAUC={study.best_value:.4f}',
                     (best_n, best_d),
                     xytext=(15, -15),
                     textcoords='offset points',
                     bbox=dict(boxstyle="round,pad=0.3", fc="white", ec="red", alpha=0.7),
                     arrowprops=dict(arrowstyle="->", color="red"))

    plt.xlabel('n_estimators')
    plt.ylabel('max_depth')
    plt.title('Hyperparameter Performance Heatmap')
    plt.grid(True, linestyle='--', alpha=0.3)
    plt.tight_layout()
    plt.savefig('results/optuna_plots/contour_plot.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("çƒ­åŠ›å›¾å·²ä¿å­˜")

# 9. ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–
plt.figure(figsize=(12, 8))
feature_importances = pd.Series(best_model.feature_importances_, index=X_train.columns)
feature_importances.nlargest(15).sort_values().plot(kind='barh', color=sns.color_palette('viridis_r', 15))
plt.title(f'Top 15 Feature Importances (Test AUC={test_auc:.4f})')
plt.xlabel('Importance Score')
plt.grid(axis='x', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.savefig('results/optuna_plots/feature_importances.png', dpi=300, bbox_inches='tight')
plt.close()
print("ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜")

print("\nâœ… æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨å·²æˆåŠŸç”Ÿæˆå¹¶ä¿å­˜!")